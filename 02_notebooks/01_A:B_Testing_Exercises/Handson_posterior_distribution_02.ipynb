{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b8ce98-ed19-4935-999c-1a08ee9ceffa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analytical Approach to Derive Posterior Distribution\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<h3>Goal of this session:</h3>\n",
    "\n",
    "In this hands-on session, you will visually obtain and explore posterior distributions based on the Analytical Approach. The insight gained from this session will help you understand:\n",
    "- how the prior and posterior distributions are related to each other\n",
    "- how the posterior distribution changes as more data is observed\n",
    "- how the posterior distribution changes as the prior distribution changes\n",
    "\n",
    "Your observations here will help you to make informed decisions about the prior distribution and sample size in A/B testing during the next sessions.\n",
    "</div>\n",
    "\n",
    "Remember that when the prior is Beta or Gamma, the posterior distribution has a closed-form solution, and is also Beta or Gamma, respectively. We will use the `scipy.stats` module to plot the posterior distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71cae8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h3>Case of Beta Prior and Bernoulli Likelihood</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21005708",
   "metadata": {},
   "source": [
    "Here we are interested in the posterior distribution of $\\theta$ given the evidence from data and the prior distribution of $\\theta$. The posterior distribution is proportional to the product of the likelihood and the prior. If the data is generated based on a `Bernoulli` random variable with parameter $\\theta$, and the prior distribution of $\\theta$ is a `Beta`, then the posterior distribution of $\\theta$ follows a `Beta` too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e12b3d",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec251e5-abd0-4bc7-8731-4826323e8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ff226",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h5>Prior distribution as a Beta distribution</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a01d8-0345-4b44-8263-188a7fe821fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters (a0>0, b0>0)\n",
    "a0, b0 = 120,120\n",
    "\n",
    "# plot probability distribution\n",
    "x = np.linspace(0,1,100)\n",
    "\n",
    "plt.plot(x, beta.pdf(x, a0,b0), 'b-')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.title('prior Beta distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8b7d60",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>Task 1</h4>\n",
    "\n",
    "Let's vary the parameters and see how the distribution changes. \n",
    "\n",
    "1. As an example, suppose that $\\theta$ is the probability of observing head in flipping a coin. We are strongly convinced that the coin is fair. Change the parameters `a0, b0` until you get a distribution that best describes our prior belief. \n",
    "\n",
    "2. As an another example, suppose that $\\theta$ is the probability a person clicking on an ad. Our prior knowledge about this probability is poor because this is the first time we are running this campaign. So, any probability between 0 and 1 is equally likely. Change the parameters `a0, b0` until you get a distribution that best describes our prior belief. \n",
    "\n",
    "3. Following the previous example, suppose that by experience we know that the probability of clicking on an ad is between 0.1 and 0.2. Change the parameters `a0, b0` until you get a distribution that best describes our prior belief.\n",
    "\n",
    "4. Based on your observations in the previous questions, argue whether these priors were informative or not.\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24122e0a-1eb1-498b-9230-b4f6316293cd",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ade860",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h5>Likelihood based on a Bernoulli distribution</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c39081-7d94-4cea-92f9-0301d4273b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters: N is the number of trials, and n_success is the number of successes\n",
    "N, n_success = 10, 9\n",
    "plt.plot(x, x**n_success * (1-x)**(N-n_success), 'r')\n",
    "\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.title('likelihood function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cce2b4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>Task 2</h4>\n",
    "\n",
    "Let's vary the parameters and see how the distribution changes. \n",
    "\n",
    "1. Consider again the example of flipping a coin where $\\theta$ is the probability of head. Using `N=10` trials, what should the value for `n_success` be in order to consider the coin as a fair one? Is the shape of the likelihood in line with your expectation?\n",
    "\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0267e-e962-4abf-be94-6a9127e68344",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7123f310",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h5>Posterior distribution as a Beta distribution</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34bbf2e-5217-466d-8472-abacbe078a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to set the parameters because they are already derived based on the prior and the likelihood\n",
    "a, b = a0 + n_success, N - n_success + b0\n",
    "print(a,b)\n",
    "\n",
    "plt.plot(x, beta.pdf(x, a, b), 'blueviolet')\n",
    "plt.title('posterior Beta distribution')\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4862cd6",
   "metadata": {},
   "source": [
    "Let's put all the three plots together in a single figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5600127-4dde-4984-93c3-559702e832e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create all plots in a row\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "# set the parameters (a>0, b>0, N>=n_success>0)\n",
    "a, b = 1000, 1000\n",
    "N = 1000\n",
    "n_success = 200\n",
    "\n",
    "# create a grid of theta values\n",
    "theta = np.linspace(0,1,100)\n",
    "\n",
    "# plot Bernoulli likelihood\n",
    "axes[0].plot(theta, theta**n_success * (1-theta)**(N-n_success), 'r')\n",
    "axes[0].set_xlabel(r'$\\theta$')\n",
    "axes[0].set_title('Bernoulli likelihood')\n",
    "axes[0].grid(axis='x', color='0.95')\n",
    "\n",
    "# plot probability distribution\n",
    "axes[1].plot(theta, beta.pdf(theta, a,b), 'b-', label='prior')\n",
    "axes[1].plot(theta, beta.pdf(theta, a+n_success, b+N-n_success), 'blueviolet', label='posterior')\n",
    "\n",
    "axes[1].set_xlabel(r'$\\theta$')\n",
    "axes[1].set_title('prior and posterior distributions')\n",
    "axes[1].legend(loc='best', frameon=False)\n",
    "axes[1].grid(axis='x', color='0.95')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72d76bd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>Task 3</h4>\n",
    "\n",
    "Observe how the posterior distribution changes with the prior and likelihood. \n",
    "\n",
    "1. Fix `a = 1000, b = 1000` so that you get a strong prior. According to this prior you strongy believe that the coin is fair, i.e. about half of the times you should get a head. Now, you flip the coin 10 times and observe only 2 heads. What is your posterior belief about the fairness of the coin?\n",
    "\n",
    "2. In the previous case, the sample size of 10 probably didn't change your prior belief. Now, increase the sample size to 1000 while keeping the same success rate. What is your posterior belief about the fairness of the coin?\n",
    "\n",
    "3. Suppose that you have sent a robot on a newly discovered planet to collect soil samples. You have no prior knowledge about the soil composition of the planet and whether they are rich in iron or not. The robot collects 10 samples and finds that 2 of them are rich in iron. Setup the prior and likelihood parameters based on this information, run the code and discuss the outcome. What is your posterior belief about the soil composition of the planet? In particular, was the 10 samples enough to change your prior belief?\n",
    "\n",
    "4. Based on your findings in the questions above, discuss the effect of the sample size on the posterior distribution.\n",
    "\n",
    "\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c6c7d-7dd5-4bc7-ada2-b1dbe6057528",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec97d8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h2>Bonus Exercise</h2>\n",
    "\n",
    "<h3>Case of Gamma Prior and Exponential Likelihood</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5210cee8",
   "metadata": {},
   "source": [
    "Similar to the Beta distribution which is conjugate to the Bernoulli distribution, the Gamma distribution is conjugate to the Exponential distribution. This means that if we have a Gamma prior distribution and we observe data from a Exponential distribution, then the posterior distribution is also a Gamma distribution. This is a very useful property, because it means that we can update our beliefs about the parameters of a Gamma distribution in a closed-form way. \n",
    "\n",
    "Suppose that a number of visitors have visited an exhibition and made donations. Let's assume that the donation amount is exponentially distributed with rate $\\lambda$. If we assume that the prior distribution of $\\lambda$ is a `Gamma`, then luckily the posterior distribution of $\\lambda$ is also `Gamma`.\n",
    "\n",
    "Start by importing the `gamma` function from the `scipy.stats` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdcfbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the prior, likelihood and posterior Gamma distributions in one row of plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "# set the parameters of the prior (a>0, b>0)\n",
    "a, b = 1000, 1000\n",
    "\n",
    "# set the parameters of the likelihood \n",
    "# number of payers and total pay\n",
    "n_payers, total_pay = 100, 100*10\n",
    "\n",
    "# create a grid of lambda values\n",
    "lamda = np.linspace(0, 2, 100)\n",
    "\n",
    "# plot exponential likelihood\n",
    "axes[0].plot(lamda, (lamda**n_payers) * np.exp(-lamda*total_pay) , 'r',)\n",
    "\n",
    "axes[0].set_xlabel(r'$\\lambda$')\n",
    "axes[0].set_title('Exponential likelihood')\n",
    "axes[0].grid()\n",
    "\n",
    "# plot probability distribution\n",
    "axes[1].plot(lamda, gamma.pdf(lamda, a=a, scale=1/b), 'b', label='prior')\n",
    "axes[1].plot(lamda, gamma.pdf(lamda, a=a+n_payers, scale=1/(b+total_pay)), 'blueviolet', label='posterior')\n",
    "\n",
    "axes[1].set_xlabel(r'$\\lambda$')\n",
    "axes[1].set_title('prior and posterior distributions')\n",
    "axes[1].legend(loc='best', frameon=False)\n",
    "axes[1].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59620e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4>Task 4</h4>\n",
    "\n",
    "Observe how the posterior distribution changes with the prior and likelihood. \n",
    "\n",
    "1. From previous exhibitions you know that on average each visitor donates 1 dollar. So, let's fix `a = 1000, b = 1000` to get a strong prior. Just recently, you got 10 new visitors and recieved a sum of 100 dollars. So on average each visitor donated 10 dollars. This is on average 10 times more than what you have recieved from previous exhibitions. What is your posterior belief about the average donation amount? did the 10 new visitors change your prior belief?\n",
    "\n",
    "2. In the previous case, the sample size of 10 probably didn't change your prior belief much. Now, increase the sample size to 100 while keeping the same average donation per person. What is your posterior belief about the average donation amount?\n",
    "\n",
    "3. Based on your findings in the questions above, discuss the effect of the sample size on the posterior distribution.\n",
    "\n",
    "\n",
    "<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1295733c-eb23-4411-8617-60f436f3aa5a",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "Write your answer here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
